{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Agent RL Analysis - Isaac Sim RRT Planner\n",
    "Analysis of discrete and continuous algorithms across seeds 42 and 123"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "# Set Linux Libertine font (with fallback to serif fonts)\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "# Try to use Linux Libertine, fallback to Times New Roman or other serif fonts\n",
    "available_fonts = [f.name for f in fm.fontManager.ttflist]\n",
    "if 'Linux Libertine' in available_fonts:\n",
    "    plt.rcParams['font.family'] = 'Linux Libertine'\n",
    "elif 'Linux Libertine O' in available_fonts:\n",
    "    plt.rcParams['font.family'] = 'Linux Libertine O'\n",
    "elif 'Times New Roman' in available_fonts:\n",
    "    plt.rcParams['font.family'] = 'Times New Roman'\n",
    "else:\n",
    "    plt.rcParams['font.family'] = 'serif'\n",
    "    plt.rcParams['font.serif'] = ['Times New Roman', 'DejaVu Serif', 'Liberation Serif']\n",
    "\n",
    "print(f\"Using font: {plt.rcParams['font.family']}\")\n",
    "\n",
    "# Set font weights to normal (not bold)\n",
    "plt.rcParams['font.weight'] = 'normal'\n",
    "plt.rcParams['axes.titleweight'] = 'normal'\n",
    "plt.rcParams['axes.labelweight'] = 'normal'\n",
    "\n",
    "# Set style for sharper, clearer text\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"notebook\", font_scale=1.2)  # Larger font scale for better readability\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['figure.dpi'] = 150  # Higher DPI for sharper text\n",
    "plt.rcParams['savefig.dpi'] = 150  # Higher DPI for saved figures\n",
    "plt.rcParams['text.antialiased'] = True  # Enable antialiasing\n",
    "plt.rcParams['axes.edgecolor'] = '#333333'  # Sharper edge color\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"MULTI-AGENT RL ANALYSIS - ISAAC SIM RRT PLANNER\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Color Palettes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define color palette for selected algorithms\n",
    "discrete_colors = {\n",
    "    'DDQN + SAC': '#1f77b4',\n",
    "    'PER-DDQN-Light + SAC': '#d62728',\n",
    "    'PPO-Discrete + SAC': '#8c564b',\n",
    "    'Heuristic': '#7f7f7f'\n",
    "}\n",
    "\n",
    "continuous_colors = {\n",
    "    'PPO-Continuous+MASAC': '#8c564b',\n",
    "    'SAC-Continuous+MASAC': '#e377c2',\n",
    "    'TD3+MASAC': '#17becf',\n",
    "    'DDPG+MASAC': '#bcbd22',\n",
    "    'DDQN+MASAC': '#1f77b4',  # From discrete\n",
    "    'SAC-Discrete+MASAC': '#e377c2',  # SAC from discrete (same color as continuous SAC)\n",
    "    'Heuristic': '#7f7f7f'\n",
    "}\n",
    "\n",
    "print(\"✅ Color palettes defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Loading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_timestep_data(seeds=[42, 123], data_type='discrete'):\n",
    "    \"\"\"Load timestep data for specified seeds and data type\"\"\"\n",
    "    all_data = []\n",
    "    \n",
    "    for seed in seeds:\n",
    "        csv_path = Path(f\"two_agent_results/{data_type}/seed_{seed}/timestep_results.csv\")\n",
    "        if csv_path.exists():\n",
    "            df = pd.read_csv(csv_path)\n",
    "            df['seed'] = seed\n",
    "            all_data.append(df)\n",
    "            print(f\"✅ Loaded {len(df)} timesteps from {data_type}/seed_{seed}\")\n",
    "        else:\n",
    "            print(f\"⚠️  File not found: {csv_path}\")\n",
    "    \n",
    "    if all_data:\n",
    "        combined = pd.concat(all_data, ignore_index=True)\n",
    "        return combined\n",
    "    return None\n",
    "\n",
    "def load_episode_data(seeds=[42, 123], data_type='discrete'):\n",
    "    \"\"\"Load episode data for specified seeds and data type\"\"\"\n",
    "    all_data = []\n",
    "    \n",
    "    for seed in seeds:\n",
    "        csv_path = Path(f\"two_agent_results/{data_type}/seed_{seed}/episode_results.csv\")\n",
    "        if csv_path.exists():\n",
    "            df = pd.read_csv(csv_path)\n",
    "            df['seed'] = seed\n",
    "            all_data.append(df)\n",
    "            print(f\"✅ Loaded {len(df)} episodes from {data_type}/seed_{seed}\")\n",
    "        else:\n",
    "            print(f\"⚠️  File not found: {csv_path}\")\n",
    "    \n",
    "    if all_data:\n",
    "        combined = pd.concat(all_data, ignore_index=True)\n",
    "        return combined\n",
    "    return None\n",
    "\n",
    "print(\"✅ Data loading functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load All Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nLoading Discrete Data...\")\n",
    "discrete_timestep_df = load_timestep_data(seeds=[42, 123], data_type='discrete')\n",
    "discrete_episode_df = load_episode_data(seeds=[42, 123], data_type='discrete')\n",
    "\n",
    "print(\"\\nLoading Continuous Data...\")\n",
    "continuous_timestep_df = load_timestep_data(seeds=[42, 123], data_type='continuous')\n",
    "continuous_episode_df = load_episode_data(seeds=[42, 123], data_type='continuous')\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Compute Metrics (Following analyze_both_seeds_combined.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_by_episode(df, selected_models=None, target_episodes=[2, 4, 6, 8, 10, 12, 14, 16, 18]):\n",
    "    \"\"\"Compute average metrics across both seeds for each episode milestone\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # Rename models from MASAC to SAC format\n",
    "    model_rename_map = {\n",
    "        'DDQN+MASAC': 'DDQN + SAC',\n",
    "        'PER-DDQN-Light+MASAC': 'PER-DDQN-Light + SAC',\n",
    "        'PPO-Discrete+MASAC': 'PPO-Discrete + SAC',\n",
    "        'Heuristic': 'Heuristic'\n",
    "    }\n",
    "    \n",
    "    for model in df['model'].unique():\n",
    "        # Skip models not in selected list\n",
    "        if selected_models and model not in selected_models:\n",
    "            continue\n",
    "            \n",
    "        model_data = df[df['model'] == model].copy()\n",
    "        \n",
    "        # Rename model\n",
    "        display_name = model_rename_map.get(model, model)\n",
    "        results[display_name] = {\n",
    "            'episodes': [],\n",
    "            'success_rate': [],\n",
    "            'reward': [],\n",
    "            'distance': [],\n",
    "            'time': []\n",
    "        }\n",
    "        \n",
    "        # For each target episode, compute average across both seeds\n",
    "        for target_ep in target_episodes:\n",
    "            # Collect data from both seeds up to target episode\n",
    "            all_success_rates = []\n",
    "            all_rewards = []\n",
    "            all_distances = []\n",
    "            all_times = []\n",
    "            \n",
    "            for seed in sorted(model_data['seed'].unique()):\n",
    "                seed_data = model_data[model_data['seed'] == seed].copy()\n",
    "                seed_data = seed_data.sort_values('episode').reset_index(drop=True)\n",
    "                \n",
    "                # Get data up to target episode (1-indexed)\n",
    "                if target_ep <= len(seed_data):\n",
    "                    subset = seed_data.iloc[:target_ep]\n",
    "                    \n",
    "                    # Success rate: (total cubes picked up to this episode) / (target_ep * cubes per episode) * 100\n",
    "                    num_cubes_per_episode = subset['num_cubes'].iloc[0]\n",
    "                    total_cubes = target_ep * num_cubes_per_episode\n",
    "                    total_cubes_picked = subset['cubes_picked'].sum()\n",
    "                    success_rate = (total_cubes_picked / total_cubes) * 100\n",
    "                    all_success_rates.append(success_rate)\n",
    "                    \n",
    "                    # Reward: mean of total_reward up to this episode\n",
    "                    if model != 'Heuristic':\n",
    "                        reward = subset['total_reward'].mean()\n",
    "                        all_rewards.append(reward)\n",
    "                    \n",
    "                    # Distance: mean of total_distance_reduced up to this episode\n",
    "                    distance = subset['total_distance_reduced'].mean()\n",
    "                    all_distances.append(distance)\n",
    "                    \n",
    "                    # Time: mean of total_time_saved up to this episode\n",
    "                    time_saved = subset['total_time_saved'].mean()\n",
    "                    all_times.append(time_saved)\n",
    "            \n",
    "            # Average across seeds\n",
    "            if all_success_rates:\n",
    "                results[display_name]['episodes'].append(target_ep)\n",
    "                results[display_name]['success_rate'].append(np.mean(all_success_rates))\n",
    "                results[display_name]['reward'].append(np.mean(all_rewards) if all_rewards else None)\n",
    "                results[display_name]['distance'].append(np.mean(all_distances))\n",
    "                results[display_name]['time'].append(np.mean(all_times))\n",
    "    \n",
    "    return results\"\n",
    "\n",
    "print(\"✅ Metric computation functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Plotting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar_with_error(mean_std_data, metric_key_mean, metric_key_std, ylabel, color_map, title):\n",
    "    \"\"\"Plot bar chart with error bars (mean ± std across seeds)\"\"\"\n",
    "    \n",
    "    with sns.axes_style(\"whitegrid\", rc={'font.family': plt.rcParams['font.family']}):\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        \n",
    "        models = list(mean_std_data.keys())\n",
    "        means = [mean_std_data[m][metric_key_mean] for m in models]\n",
    "        stds = [mean_std_data[m][metric_key_std] for m in models]\n",
    "        colors = [color_map.get(m, '#000000') for m in models]\n",
    "        \n",
    "        x_pos = np.arange(len(models))\n",
    "        \n",
    "        # Filter out None values for reward (Heuristic has no reward)\n",
    "        valid_indices = [i for i, m in enumerate(means) if m is not None]\n",
    "        valid_models = [models[i] for i in valid_indices]\n",
    "        valid_means = [means[i] for i in valid_indices]\n",
    "        valid_stds = [stds[i] for i in valid_indices]\n",
    "        valid_colors = [colors[i] for i in valid_indices]\n",
    "        valid_x_pos = np.arange(len(valid_models))\n",
    "        \n",
    "        ax.bar(valid_x_pos, valid_means, yerr=valid_stds, capsize=5, \n",
    "               color=valid_colors, alpha=0.8, edgecolor='black', linewidth=1.2)\n",
    "        \n",
    "        ax.set_xlabel('Model', fontsize=12)\n",
    "        ax.set_ylabel(ylabel, fontsize=12)\n",
    "        ax.set_title(title, fontsize=14, pad=15)\n",
    "        ax.set_xticks(valid_x_pos)\n",
    "        ax.set_xticklabels(valid_models, rotation=15, ha='right')\n",
    "        \n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.grid(True, alpha=0.3, linestyle='--', linewidth=0.5)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "def plot_metric_by_episode(metrics_data, metric_key, ylabel, color_map, title):\n",\n",
    "    \"\"\"Plot metric across episodes (average across both seeds, no error bars)\"\"\"\n",
    "    \n",
    "    with sns.axes_style(\"whitegrid\", rc={'font.family': plt.rcParams['font.family']}):\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        \n",
    "        for model, data in metrics_data.items():\n",
    "            episodes = data['episodes']\n",
    "            values = data[metric_key]\n",
    "            \n",
    "            # Skip if all values are None (e.g., Heuristic reward)\n",
    "            if all(v is None for v in values):\n",
    "                continue\n",
    "            \n",
    "            color = color_map.get(model, '#000000')\n",
    "            ax.plot(episodes, values, marker='o', label=model, color=color, \n",
    "                   linewidth=2, markersize=6)\n",
    "        \n",
    "        ax.set_xlabel('Episodes', fontsize=12)\n",
    "        ax.set_ylabel(ylabel, fontsize=12)\n",
    "        ax.set_title(title, fontsize=12, pad=15)\n",
    "        \n",
    "        # Set x-axis ticks to match target episodes\n",
    "        ax.set_xticks([2, 4, 6, 8, 10, 12, 14, 16, 18])\n",
    "        \n",
    "        ax.legend(loc='best', frameon=True, fontsize=10)\n",
    "        \n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.grid(True, alpha=0.3, linestyle='--', linewidth=0.5)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "print("✅ Plotting functions defined")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Compute Metrics for Discrete Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPUTING METRICS FOR SELECTED DISCRETE ALGORITHMS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Selected models for analysis\n",
    "reward_models = ['DDQN+MASAC', 'PER-DDQN-Light+MASAC', 'PPO-Discrete+MASAC']\n",
    "all_models = ['DDQN+MASAC', 'Heuristic', 'PER-DDQN-Light+MASAC']\n",
    "\n",
    "# Compute metrics by episode (average across both seeds)\n",
    "metrics_by_episode_reward = compute_metrics_by_episode(discrete_episode_df, selected_models=reward_models)\n",
    "metrics_by_episode_all = compute_metrics_by_episode(discrete_episode_df, selected_models=all_models)\n",
    "\n",
    "print(\"\\n✅ Metrics computed for selected models\")\n",
    "print(f\"Reward models: {reward_models}\")\n",
    "print(f\"All metrics models: {all_models}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Plot Reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PLOTTING REWARD\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "plot_metric_by_episode(metrics_by_episode_reward, 'reward', \n",
    "                       'Average Reward', discrete_colors, 'Average Reward')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Plot Pick Success Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PLOTTING PICK SUCCESS RATE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "plot_metric_by_episode(metrics_by_episode_all, 'success_rate', \n",
    "                       'Pick Success Rate (%)', discrete_colors, 'Pick Success Rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Plot Distance Reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PLOTTING DISTANCE REDUCED\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "plot_metric_by_episode(metrics_by_episode_all, 'distance', \n",
    "                       'Distance Reduced (m)', discrete_colors, 'Distance Reduced')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Plot Time Saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PLOTTING TIME SAVED\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "plot_metric_by_episode(metrics_by_episode_all, 'time', \n",
    "                       'Time Saved (s)', discrete_colors, 'Time Saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"✅ ALL PLOTS GENERATED SUCCESSFULLY!\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nMetrics Calculated Following analyze_both_seeds_combined.py:\")\n",
    "print(\"- Success Rate: (total cubes picked) / (17 episodes × 9 cubes) × 100\")\n",
    "print(\"- Reward: mean of total_reward across all 17 episodes\")\n",
    "print(\"- Distance: mean of total_distance_reduced across all 17 episodes\")\n",
    "print(\"- Time: mean of total_time_saved across all 17 episodes\")\n",
    "print(\"\\nAll metrics show Mean ± Std across seeds 42 and 123\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

