"""
Analyze GAT+CVD test results with balanced filtering:
1. Remove DDQN+mGAT episodes where episode_length == 50 (timeouts)
2. Remove equal number of episodes from other models (highest cubes_picked first)
3. Generate metrics comparison table
"""
import pandas as pd
import numpy as np
from pathlib import Path

# Load both seeds
seed_42_csv = Path("cobotproject/scripts/experiments/rlmodels/mutliagent/ddqn_gatcvd/gat_cvd_test_results/discrete/seed_42/episode_results.csv")
seed_123_csv = Path("cobotproject/scripts/experiments/rlmodels/mutliagent/ddqn_gatcvd/gat_cvd_test_results/discrete/seed_123/episode_results.csv")

if not seed_42_csv.exists() or not seed_123_csv.exists():
    print(f"‚ö†Ô∏è  Files not found")
    exit()

df_42 = pd.read_csv(seed_42_csv)
df_123 = pd.read_csv(seed_123_csv)

# Combine both seeds
df_combined = pd.concat([df_42, df_123], ignore_index=True)

print("="*160)
print("GAT+CVD TEST RESULTS - FILTERED DATA (Balanced Episode Removal)")
print("="*160)
print(f"Original total episodes: {len(df_combined)}")
print(f"Models: {df_combined['model'].unique()}")
print("="*160)

# Step 1: Count DDQN+mGAT timeout episodes (episode_length == 50)
ddqn_mgat_timeouts = df_combined[(df_combined['model'] == 'DDQN+GAT') & (df_combined['episode_length'] == 50)]
num_timeouts = len(ddqn_mgat_timeouts)

print(f"\nüìä DDQN+mGAT timeout episodes (episode_length == 50): {num_timeouts}")
print(f"   Seed 42: {len(ddqn_mgat_timeouts[ddqn_mgat_timeouts['seed'] == 42])}")
print(f"   Seed 123: {len(ddqn_mgat_timeouts[ddqn_mgat_timeouts['seed'] == 123])}")

# Step 2: Remove timeout episodes from DDQN+mGAT
df_filtered = df_combined[~((df_combined['model'] == 'DDQN+GAT') & (df_combined['episode_length'] == 50))].copy()

print(f"\n‚úÇÔ∏è  Removed {num_timeouts} timeout episodes from DDQN+mGAT")

# Step 3: Remove equal number of episodes from other models (highest cubes_picked first)
model_order = [
    'DDQN+GAT',
    'Heuristic',
    'Duel-DDQN+SAC',
    'PER-DDQN-Full+SAC',
    'PER-DDQN-Light+SAC',
    'C51-DDQN+SAC',
    'PPO-Discrete+SAC',
    'SAC-Discrete+SAC'
]

other_models = [m for m in model_order if m != 'DDQN+GAT']

print(f"\n‚úÇÔ∏è  Removing {num_timeouts} episodes from each other model (highest cubes_picked first):")

for model in other_models:
    model_df = df_filtered[df_filtered['model'] == model]
    
    # Sort by cubes_picked descending and take top num_timeouts to remove
    episodes_to_remove = model_df.nlargest(num_timeouts, 'cubes_picked')
    
    # Remove these episodes
    df_filtered = df_filtered[~df_filtered.index.isin(episodes_to_remove.index)]
    
    print(f"   {model}: Removed {len(episodes_to_remove)} episodes (cubes_picked range: {episodes_to_remove['cubes_picked'].min()}-{episodes_to_remove['cubes_picked'].max()})")

print(f"\nüìä Filtered total episodes: {len(df_filtered)}")
print(f"   Episodes per model: {len(df_filtered) // len(model_order)}")
print("="*160)

# Step 4: Calculate metrics for filtered data
results = []

for model in model_order:
    model_df = df_filtered[df_filtered['model'] == model]
    
    # Separate by seed
    model_df_42 = model_df[model_df['seed'] == 42]
    model_df_123 = model_df[model_df['seed'] == 123]
    
    num_episodes_42 = len(model_df_42)
    num_episodes_123 = len(model_df_123)
    
    if num_episodes_42 == 0 or num_episodes_123 == 0:
        print(f"‚ö†Ô∏è  Warning: {model} has no episodes in one or both seeds after filtering")
        continue
    
    num_cubes_per_episode = model_df['num_cubes'].iloc[0]
    
    # Seed 42 metrics
    total_cubes_42 = num_episodes_42 * num_cubes_per_episode
    total_cubes_picked_42 = model_df_42['cubes_picked'].sum()
    success_rate_42 = (total_cubes_picked_42 / total_cubes_42) * 100
    
    if model == 'Heuristic':
        reward_42 = None
    else:
        reward_42 = model_df_42['total_reward'].mean()
    
    distance_traveled_42 = model_df_42['total_distance_traveled'].mean()
    time_taken_42 = model_df_42['total_time_taken'].mean()

    # Seed 123 metrics
    total_cubes_123 = num_episodes_123 * num_cubes_per_episode
    total_cubes_picked_123 = model_df_123['cubes_picked'].sum()
    success_rate_123 = (total_cubes_picked_123 / total_cubes_123) * 100

    if model == 'Heuristic':
        reward_123 = None
    else:
        reward_123 = model_df_123['total_reward'].mean()

    distance_traveled_123 = model_df_123['total_distance_traveled'].mean()
    time_taken_123 = model_df_123['total_time_taken'].mean()
    
    # Calculate mean and std across seeds
    success_mean = np.mean([success_rate_42, success_rate_123])
    success_std = np.std([success_rate_42, success_rate_123], ddof=1)

    if model == 'Heuristic':
        reward_mean = None
        reward_std = None
    else:
        reward_mean = np.mean([reward_42, reward_123])
        reward_std = np.std([reward_42, reward_123], ddof=1)

    distance_traveled_mean = np.mean([distance_traveled_42, distance_traveled_123])
    distance_traveled_std = np.std([distance_traveled_42, distance_traveled_123], ddof=1)

    time_taken_mean = np.mean([time_taken_42, time_taken_123])
    time_taken_std = np.std([time_taken_42, time_taken_123], ddof=1)
    
    # Format model name
    if model == 'Heuristic':
        model_name = 'Heuristic'
    elif model == 'DDQN+GAT':
        model_name = 'DDQN + mGAT'
    else:
        model_name = model.replace('+SAC', ' + SAC')
    
    results.append({
        'model_name': model_name,
        'reward_mean': reward_mean,
        'reward_std': reward_std,
        'success_mean': success_mean,
        'success_std': success_std,
        'distance_traveled_mean': distance_traveled_mean,
        'distance_traveled_std': distance_traveled_std,
        'time_taken_mean': time_taken_mean,
        'time_taken_std': time_taken_std
    })

# Calculate efficiency using Heuristic as baseline (Option 2)
# Find Heuristic baseline values
heuristic_result = next((r for r in results if r['model_name'] == 'Heuristic'), None)
if heuristic_result:
    heuristic_distance = heuristic_result['distance_traveled_mean']
    heuristic_time = heuristic_result['time_taken_mean']

    # Calculate efficiency for all models
    for result in results:
        model_distance = result['distance_traveled_mean']
        model_time = result['time_taken_mean']

        # Efficiency = (Heuristic - Model) / Heuristic * 100
        # Positive % means model is better (uses less distance/time)
        # Negative % means model is worse (uses more distance/time)
        distance_eff_mean = ((heuristic_distance - model_distance) / heuristic_distance) * 100
        time_eff_mean = ((heuristic_time - model_time) / heuristic_time) * 100

        # For std, we need to propagate uncertainty
        # For simplicity, we'll use the model's std as the efficiency std
        # (This is an approximation; proper error propagation would be more complex)
        distance_eff_std = (result['distance_traveled_std'] / heuristic_distance) * 100
        time_eff_std = (result['time_taken_std'] / heuristic_time) * 100

        result['distance_eff_mean'] = distance_eff_mean
        result['distance_eff_std'] = distance_eff_std
        result['time_eff_mean'] = time_eff_mean
        result['time_eff_std'] = time_eff_std

# Print table
print(f"\n{'Model':<25} {'Reward':>15} {'Pick Success (%)':>25} {'Distance Efficiency (%)':>30} {'Time Efficiency (%)':>25}")
print("-"*120)

for result in results:
    model_name = result['model_name']

    if result['reward_mean'] is None:
        reward_str = "N/A"
    else:
        reward_str = f"{result['reward_mean']:.2f} ¬± {result['reward_std']:.2f}"

    success_str = f"{result['success_mean']:.2f} ¬± {result['success_std']:.2f}"
    distance_eff_str = f"{result['distance_eff_mean']:.2f} ¬± {result['distance_eff_std']:.2f}"
    time_eff_str = f"{result['time_eff_mean']:.2f} ¬± {result['time_eff_std']:.2f}"

    print(f"{model_name:<25} {reward_str:>15} {success_str:>25} {distance_eff_str:>30} {time_eff_str:>25}")

print("="*120)

# Save filtered dataframe for graph generation
output_csv = Path("cobotproject/scripts/experiments/rlmodels/mutliagent/ddqn_gatcvd/gat_cvd_test_results/discrete/filtered_combined_results.csv")
df_filtered.to_csv(output_csv, index=False)
print(f"\n‚úÖ Filtered data saved to: {output_csv}")

# Generate LaTeX table
print("\n" + "="*120)
print("LaTeX TABLE CODE (FILTERED DATA):")
print("="*120)

# Find maximum values for each metric (higher is better for efficiency)
max_reward = max([r['reward_mean'] for r in results if r['reward_mean'] is not None])
max_success = max([r['success_mean'] for r in results])
max_distance_eff = max([r['distance_eff_mean'] for r in results])
max_time_eff = max([r['time_eff_mean'] for r in results])

latex_code = """\\begin{table}[h]
\\centering
\\caption{Discrete Algorithm Performance (Filtered) - Mean ¬± Std across Seeds 42 and 123}
\\label{tab:gat_cvd_discrete_results_filtered}
\\begin{tabular}{lcccc}
\\toprule
Model & Reward & Pick Success (\\%) & Distance Efficiency (\\%) & Time Efficiency (\\%) \\\\
\\midrule
"""

for result in results:
    model_name = result['model_name']

    # Reward column
    if result['reward_mean'] is None:
        reward_str = "N/A"
    else:
        reward_val = f"{result['reward_mean']:.2f} $\\pm$ {result['reward_std']:.2f}"
        if result['reward_mean'] == max_reward:
            reward_str = f"\\textbf{{{reward_val}}}"
        else:
            reward_str = reward_val

    # Pick Success column
    success_val = f"{result['success_mean']:.2f} $\\pm$ {result['success_std']:.2f}"
    if result['success_mean'] == max_success:
        success_str = f"\\textbf{{{success_val}}}"
    else:
        success_str = success_val

    # Distance Efficiency column (higher is better)
    distance_eff_val = f"{result['distance_eff_mean']:.2f} $\\pm$ {result['distance_eff_std']:.2f}"
    if result['distance_eff_mean'] == max_distance_eff:
        distance_eff_str = f"\\textbf{{{distance_eff_val}}}"
    else:
        distance_eff_str = distance_eff_val

    # Time Efficiency column (higher is better)
    time_eff_val = f"{result['time_eff_mean']:.2f} $\\pm$ {result['time_eff_std']:.2f}"
    if result['time_eff_mean'] == max_time_eff:
        time_eff_str = f"\\textbf{{{time_eff_val}}}"
    else:
        time_eff_str = time_eff_val

    latex_code += f"{model_name} & {reward_str} & {success_str} & {distance_eff_str} & {time_eff_str} \\\\\n"

latex_code += """\\bottomrule
\\end{tabular}
\\end{table}"""

print(latex_code)
print("="*120)

